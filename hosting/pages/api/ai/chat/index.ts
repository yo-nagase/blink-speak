import { ChatOpenAI } from "langchain/chat_models/openai";
import { HumanChatMessage, HumanMessage, SystemChatMessage } from "langchain/schema";

import { OpenAI } from "langchain/llms/openai";
import { loadSummarizationChain } from "langchain/chains";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
import * as fs from "fs";
import { Chat } from "openai/resources";


export default async function handler(req, res) {
  console.log("ğŸµğŸµğŸµğŸµ", req.query);
  if (req.method === "GET") {
    if (req.query.param1 == "sync") {
      //   ã“ã‚Œã§ãƒãƒ£ãƒƒãƒˆã¯å®Ÿç¾ã§ãã‚‹
      const chat2 = new ChatOpenAI({
        streaming: true,
        //modelName: "gpt-3.5-turbo-0613",
        modelName: "gpt-3.5-turbo-1106",
        temperature: 0,
        callbacks: [
          {
            handleLLMNewToken(token: string) {
              process.stdout.write(token);
            },
          },
        ],
        // modelKwargs: { "response_format": "json" }
      });
    } else {
      const id = req.query.id;
      const question = req.query.question ?? "xxxxx";
      const answer = req.query.answer ?? "xxxxx";

      console.log("question", question);
      console.log("answer", answer);

      const chat = new ChatOpenAI({
        temperature: 0,
        verbose: true,
      });

      // start time so that we can measure how long it takes to get a response
      const start = new Date().getTime();

      const responseB = await chat.invoke([
        // new SystemChatMessage(
        //   `your goal is to give a sentence in Japanese to requester and user gives you translated answer in English,
        // when you get answer from user, judge if the answer is natural or not,
        // when user answer the question,
        // return response in json format as indicated below.
        // the response will be used in the client system, so please make sure that JSON format is correct. 

        // \`\`\`:json
        // {
        //  adivice : string, // advice to improve the answer
        //  natural_score:number,  // 100 is the best indicate how natural the answer is
        //  grammer_score: number,  // 100 is the best score, how grammerly correct the answer is
        //  proposals:string[] // 1-5 proposals to improve the answer
        // }
        // \`\`\`

        // YOUR QUESTION:

        // `
        // ),
        new HumanMessage(`
ã‚ãªãŸã®å½¹å‰²ã¯è³ªå•ã«å¯¾ã—ã¦ãƒ¦ãƒ¼ã‚¶ãŒç­”ãˆãŸè‹±æ–‡ã‚’è©•ä¾¡ã—ã€å›ç­”ã™ã‚‹ã“ã¨ã§ã™ã€‚è©•ä¾¡ã‚¹ã‚³ã‚¢ã¯ã€1-100ã®ç‚¹æ•°ã§ç­”ãˆã¾ã™ã€‚è©•ä¾¡ã®ãƒã‚¤ãƒ³ãƒˆã¯ãã‚Œãã‚Œä»¥ä¸‹ã«ç¤ºã—ãŸJSONã®ã‚³ãƒ¡ãƒ³ãƒˆã«å¾“ã„ã¾ã™ã€‚
è©•ä¾¡çµæœã¯JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å›ç­”ã—ã€ä»¥ä¸‹ã®é …ç›®ã‚’å«ã‚ã¦ãã ã•ã„ã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯JSONã®ã¿ã§ã€ãã‚Œä»¥å¤–ã®ä½™åˆ†ãªæ–‡å­—åˆ—ã®è¿½åŠ ã¯ã—ãªã„ã§ãã ã•ã„ã€‚
è©•ä¾¡ã—ãŸã‚¹ã‚³ã‚¢ã¯è‹±ä¼šè©±ã‚²ãƒ¼ãƒ ã§åˆ©ç”¨ã—ã€ã‚¹ã‚³ã‚¢ã®åˆè¨ˆã‚’å…¥åŠ›è€…åŒå£«ã§ç«¶ã„åˆã„ã¾ã™ã®ã§ã€ç‰¹ã«100ç‚¹ã¯æœ¬å½“ã«æ­£ã—ã„å ´åˆä»¥å¤–ã¯å‡ºã•ãªã„æ§˜ã«ã—ã¦ãã ã•ã„ã€‚
ã§ãã‚‹ã ã‘ç´ æ—©ãå›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚


\`\`\`
{
  "key" : string, // this is question id. set same id as you received 
  "is_correct" : boolean // the user's answer is corrct or not 
 "grammer_score" : number // if user's answer is correct grammaticaly, this score would be 100
 "natural_score" : number  //if user's expression is natural perfectly, this score would be 100
"comment_eng" : string, // give advice to user to improve the answer in English
"comment_jpn" : string, // æ—¥æœ¬èªã§æ­£è§£ã®ç‚ºã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚å•é¡Œæ–‡ã‚’å¼•ç”¨ã™ã‚‹æ™‚ã¯å•é¡Œã¨åŒã˜è‹±èªã‚’ç”¨ã„ã¦ãã ã•ã„ã€‚
"question": string, // question to user. always same sentence as below.
"user_answer" : string, // this is user's answer
"proposal_answer" :  string, // give a proposal answer in English. translation is NOT needed.and only one proposal is enough. no advice, just give a answer only.
}

\`\`\`

This is the question id: ${id}

Here is question :

\`\`\`
${question}
\`\`\`

Here is user's answer :

\`\`\`
${answer}

\`\`\`
`),
        // new SystemChatMessage(
        //   "ä»Šæœã®æœé£Ÿã¯ä½•ã‚’é£Ÿã¹ã¾ã—ãŸã‹ï¼Ÿ(Kesa no choushoku wa nani wo tabemashita ka?)"
        // ),
        // new HumanChatMessage("What do you eat for breakfast this morning?"),
      ]);
      // end time here and get the difference
      const end = new Date().getTime();
      const time = end - start;

      console.log("ğŸ¸ğŸ¸ğŸ¸ğŸ¸", { message: responseB, take: time })
      res.status(200).json({ message: responseB, take: time });
    }
  }
}
